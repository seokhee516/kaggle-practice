{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb의 사본",
      "provenance": [],
      "authorship_tag": "ABX9TyP6ru5PZCOU3TVMRpl8SaMT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seokhee516/kaggle-practice/blob/main/Binary%20classification/Porto%20Seguro%E2%80%99s%20Safe%20Driver%20Prediction/XGBoost%20CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXdfvGCLWv6s",
        "outputId": "0b1773c1-4cb2-4023-f638-0d828b87fec1"
      },
      "source": [
        "!pip install gcsfs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading gcsfs-2021.9.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting fsspec==2021.09.0\n",
            "  Downloading fsspec-2021.9.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.6)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 43.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gcsfs) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, gcsfs\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.9.0 gcsfs-2021.9.0 multidict-5.1.0 yarl-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ugJauoFS6EN"
      },
      "source": [
        "MAX_ROUNDS = 400\n",
        "OPTIMIZE_ROUNDS = False\n",
        "LEARNING_RATE = 0.07\n",
        "EARLY_STOPPING_ROUNDS = 50"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_dws87oTc0W"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numba import jit\n",
        "import time\n",
        "import gc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFh7YsiiVpKu"
      },
      "source": [
        "# Compute gini\n",
        "@jit\n",
        "def eval_gini(y_true, y_prob):\n",
        "  y_true = np.asanyarray(y_true)\n",
        "  y_true = y_true[np.argsort(y_prob)]\n",
        "  ntrue = 0\n",
        "  gini = 0\n",
        "  delta = 0\n",
        "  n = len(y_true)\n",
        "  for i in range(n-1, -1, -1):\n",
        "    y_i = y_true[i]\n",
        "    ntrue += y_i\n",
        "    gini += y_i, dela\n",
        "    delta += 1 - y_i\n",
        "  gini = 1 - 2 *gini /(ntrue * (n - ntrue))\n",
        "  return gini"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQNo9Atpmtm9"
      },
      "source": [
        "def gini_xgb(preds, dtrain):\n",
        "  labels = dtrain.get_label()\n",
        "  gini_score = -eval_gini(labels, preds)\n",
        "  return [('gini', gini_score)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEi5fsfwn9wl"
      },
      "source": [
        "def add_noise(series, noise_level):\n",
        "  return series * (1 + noise_level *np.random.randn(len(series)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytMxdA-WpTJi"
      },
      "source": [
        "def target_encode(trn_series=None,\n",
        "                  val_series=None,\n",
        "                  tst_series=None,\n",
        "                  min_samples_leaf=1,\n",
        "                  smoothing=1,\n",
        "                  noise_level=0):\n",
        "  assert len(trn_series) == (target)\n",
        "  assert trn_series.name == tst_series.name\n",
        "  temp = pd.concat([trn_series, target], axis=1)\n",
        "  averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\",\"count\"])\n",
        "  smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf)))\n",
        "  prior = target.mean()\n",
        "  averages[target.name] = prior * (1-smoothing) + averages[\"mean\"] * smoothing\n",
        "  averages.drop([\"mean\", \"count\"], axis=1, inplace = True)\n",
        "  ft_trn_series  = pd.merge(\n",
        "      trn_series.to_frame(trn_series.name),\n",
        "      averages.reset_index().rename(columns={\n",
        "          'index':target.name, targget.name:'averages'\n",
        "      }),\n",
        "      on = trn_series.name,\n",
        "      how ='left')['average'].rename(trn_series.name + '_mean').filna(prior)\n",
        "  ft_val_serieis.index = trn_series.index\n",
        "  ft_val_serieis = pe. merge(\n",
        "      val_series.to_frame(val_series.name),\n",
        "      averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "      on=val_series.name,\n",
        "      how='left'\n",
        "  )['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "  ft_tst_series.index = tst_series.test_index\n",
        "  return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBlzVitQWYSp"
      },
      "source": [
        "# Road data\n",
        "GCS_DS_PATH = \"gs://kds-e5602443d7485cc7c65ae998ed306d9f26534ba34b6cda928f9be8b0\"\n",
        "train_df = pd.read_csv(GCS_DS_PATH+'/train.csv', na_values=\"-1\")\n",
        "test_df = pd.read_csv(GCS_DS_PATH+\"/test.csv\", na_values=\"-1\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeY6C0hOX3ws"
      },
      "source": [
        "# from olivier\n",
        "train_features = [\n",
        "  \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
        "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
        "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
        "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
        "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
        "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
        "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
        "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
        "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
        "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
        "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
        "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
        "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
        "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
        "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
        "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
        "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
        "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
        "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
        "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
        "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
        "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
        "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
        "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
        "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
        "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
        "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
        "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
        "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
        "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
        "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
        "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
        "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
        "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
        "]\n",
        "# add combinations\n",
        "combs = [\n",
        "         ('ps_reg_01', 'ps_car_02_cat'),\n",
        "         ('ps_reg_01', 'ps_car_04_cat'),\n",
        "]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIsafc1iYNAq"
      },
      "source": [
        "# Process data\n",
        "id_test = test_df['id'].values\n",
        "id_train = train_df['id'].values\n",
        "y = train_df['target']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKUqgg2kaqUj",
        "outputId": "5db70698-642b-4f0a-c10f-64d675cbce7e"
      },
      "source": [
        "# 복습 필요\n",
        "start = time.time()\n",
        "for n_c, (f1, f2) in enumerate(combs):\n",
        "    name1 = f1 + \"_plus_\" + f2\n",
        "    print('current feature %60s %4d in %5.1f'\n",
        "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
        "    print('\\r' * 75, end='')\n",
        "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
        "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
        "    # Label Encode\n",
        "    lbl = LabelEncoder()\n",
        "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
        "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
        "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
        "\n",
        "    train_features.append(name1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJcZz-VleBkS"
      },
      "source": [
        "X = train_df[train_features]\n",
        "test_df = test_df[train_features]\n",
        "f_cats = [f for f in X.columns if \"_cat\" in f]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_FjJ6zSfFvx"
      },
      "source": [
        "y_valid_pred = 0*y\n",
        "y_test_pred = 0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHo5g8cefYxy"
      },
      "source": [
        "# set up folds\n",
        "K = 5\n",
        "kf = KFold(n_splits = K, random_state=1, shuffle= True)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtSjL0OHfof3"
      },
      "source": [
        "# set up classifier\n",
        "model = XGBClassifier(\n",
        "    n_estimators = MAX_ROUNDS,\n",
        "    max_depth = 4,\n",
        "    objective='binary:logistic',\n",
        "    learning_rate = LEARNING_RATE,\n",
        "    subsample=.8,\n",
        "    min_child_weight=6,\n",
        "    colsample_bytree=.8,\n",
        "    scale_pos_weight=1.6,\n",
        "    gamma=10,\n",
        "    reg_alpha=8,\n",
        "    reg_lambda=1.3\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LclgM1snggjU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f5f3ff7c-45af-4c01-dbc9-4abfca9ba3bf"
      },
      "source": [
        "# Run CV\n",
        "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
        "  y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
        "  X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :]. copy()\n",
        "  X_test = test_df.copy()\n",
        "  print(\"\\nFold \", i)\n",
        "  # Encode data\n",
        "    for f in f_cats:\n",
        "      X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f+ \"_avg\"] = target_encode(\n",
        "          trn_series = X_train[f], \n",
        "          val_series = X_valid[f], \n",
        "          tst_series = X_test[f],\n",
        "          target = y_train, \n",
        "          min_samples_leaf = 200, \n",
        "          smoothing =10, \n",
        "          noise_level = 0\n",
        "      )\n",
        "  # Run model for this fold\n",
        "  if OPTIMIZE_ROUNDS:\n",
        "    eval_set = [(X_valid, y_valid)]\n",
        "    fit_model = model.fit(X_train, y_train,\n",
        "                          eval_set = eval_set,\n",
        "                          eval_metric = gini_xgb,\n",
        "                          early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n",
        "                          verbose = False)\n",
        "    print(\"Best N trees = \", model.best_ntree_limit)\n",
        "    prin(\" Best gini = \", model.best_score)\n",
        "  else:\n",
        "    fit_model = model.fit(X_train, y_train)\n",
        "  # Generate validation predictions for this fold\n",
        "  pred = fit_model.predict_prob(X_valid)[:,1]\n",
        "  print(\"Gini = \", eval_gini(y_valid, pred))\n",
        "  y_valid_pred.iloc[test_index] = pred\n",
        "\n",
        "  # Accumulate test set predictions\n",
        "  y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
        "  \n",
        "  del X_test, X_train, X_valid, y_train\n",
        "\n",
        "y_test_pred /= K\n",
        "print(\"\\nGini for full training set:\")\n",
        "eval_gini(y,y_valid_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-af610ac37dca>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    for f in f_cats:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsvgF7OJjaX8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}